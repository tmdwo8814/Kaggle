{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19084,"status":"ok","timestamp":1686562982117,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"RwA3gcavv6-M","outputId":"1ae5c180-8482-40eb-90ae-5a6ce1236a39"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":355,"status":"ok","timestamp":1686563001061,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"at47xkJGyIRw","outputId":"d862b9d7-324d-461e-da37-48dfc9ff2e72"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/animal_detection\n"]}],"source":["%cd drive/MyDrive/animal_detection"]},{"cell_type":"markdown","metadata":{"id":"azMEfFo_a8Iq"},"source":["### Data Download & custom"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4417,"status":"ok","timestamp":1686563009138,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"7mWbwiXca8Iu","outputId":"63f3543a-935e-46b8-cca8-e1882e93cf5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"]}],"source":["!pip install kaggle"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"elapsed":11696,"status":"ok","timestamp":1686563023285,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"g5YVLzTZciMR","outputId":"d44095ee-15b2-4ce7-fb45-8739537be703"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-4c9ea366-f30c-4214-8ac5-115bf8818a72\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-4c9ea366-f30c-4214-8ac5-115bf8818a72\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving kaggle.json to kaggle.json\n"]}],"source":["# 사전 작업 : kaggle에서 API 토큰 설치 \n","# kaggle API 토큰 옮기기\n","\n","from google.colab import files \n","files.upload()\n","\n","!mkdir -p ~/.kaggle \n","!cp kaggle.json ~/.kaggle\n","\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6401,"status":"ok","timestamp":1686563039731,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"m1Z_ebbIa8Iw","outputId":"68e072b0-1c7f-434d-ac64-4ec5e1a4ba4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading kdtai-3.zip to /content/drive/MyDrive/animal_detection\n"," 98% 440M/447M [00:05<00:00, 129MB/s]\n","100% 447M/447M [00:05<00:00, 90.9MB/s]\n"]}],"source":["# data download\n","\n","!kaggle competitions download -c kdtai-3"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":13230,"status":"ok","timestamp":1686563083614,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"eFKwsLOda8Ix"},"outputs":[],"source":["# unzip\n","\n","import os\n","import zipfile\n","\n","zip_path = os.path.join(os.getcwd(), 'kdtai-3.zip')\n","unzip_path = os.getcwd()\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(unzip_path)"]},{"cell_type":"markdown","metadata":{"id":"-dHz-L-uz-C3"},"source":["### Data structures in yolo format"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":283,"status":"ok","timestamp":1686563112223,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"OA0Kmvmt_q8t","outputId":"581945b1-85a6-4932-c725-39d66d61a0dc"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/animal_detection'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["pwd"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":321,"status":"ok","timestamp":1686563128466,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"ZaA6BcOxa8Ix"},"outputs":[],"source":["# dataset 폴더에 labels, images 폴더 생성\n","\n","labels_path = os.path.join(os.getcwd(), 'dataset', 'labels')\n","images_path = os.path.join(os.getcwd(), 'dataset', 'images')\n","\n","os.makedirs(labels_path, exist_ok=True)\n","os.makedirs(images_path, exist_ok=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1686563186797,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"Gk3hTygDa8Iy","outputId":"95c118fc-c237-4c32-8b90-f70b86e7f773"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/animal_detection/dataset/images/train'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# test, train 이미지 폴더를 생성한 폴더로 이동\n","import shutil\n","\n","test_path = os.path.join(os.getcwd(), 'dataset', 'test')\n","train_path = os.path.join(os.getcwd(), 'dataset', 'train')\n","destination_path = os.path.join(os.getcwd(), 'dataset', 'images')\n","\n","shutil.move(test_path, destination_path)\n","shutil.move(train_path, destination_path)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":306,"status":"ok","timestamp":1686563236715,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"kbuZhmloa8Iy","outputId":"39b5b3e8-8340-46d0-99ed-6e8da1c69faa"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/animal_detection/dataset/labels/train_output.csv'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# test,train_output.csv -> dataset/labels\n","\n","test_csv_path = os.path.join(os.getcwd(), 'dataset', 'images', 'test', 'test_output.csv')\n","train_csv_path = os.path.join(os.getcwd(), 'dataset', 'images', 'train', 'train_output.csv')\n","csv_destination = os.path.join(os.getcwd(), 'dataset', 'labels')\n","\n","shutil.move(test_csv_path, csv_destination)\n","shutil.move(train_csv_path, csv_destination)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":714,"status":"ok","timestamp":1686563339063,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"CpDN38Uaa8Iz"},"outputs":[],"source":["import os \n","import pandas as pd\n","\n","train_df = pd.read_csv('/content/drive/MyDrive/animal_detection/dataset/labels/train_output.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/animal_detection/dataset/labels/test_output.csv')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1686563355813,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"Payrses3a8I0","outputId":"186505f5-cf9c-42d9-c5fa-545d21671568"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/animal_detection/dataset/labels\n"]}],"source":["%cd dataset/labels"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":6097,"status":"ok","timestamp":1686563395862,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"XIPE_s1Ma8I0"},"outputs":[],"source":["# train_output.csv에서 각 이미지의 annotation 파일 생성\n","\n","if not os.path.exists('train'):\n","    os.makedirs('train')\n","\n","for i in range(len(train_df)):\n","    title = train_df.iloc[i, 0]\n","    title = str(title).zfill(4)\n","  \n","\n","    data = train_df.iloc[i, 1]\n","\n","    file_path = os.path.join('train', f'{title}.txt')\n","\n","    with open(file_path, 'w') as file:\n","        file.write(data)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1741,"status":"ok","timestamp":1686563398957,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"Jd7kqrA8a8I1"},"outputs":[],"source":["# test_output.csv에서 각 이미지의 annotation파일 생성\n","\n","if not os.path.exists('test'):\n","    os.makedirs('test')\n","\n","for i in range(len(test_df)):\n","    title = test_df.iloc[i, 0]\n","    title = str(title).zfill(4)\n","\n","    data = test_df.iloc[i, 1]\n","\n","    file_path = os.path.join('test', f'{title}.txt')\n","\n","    with open(file_path, 'w') as file:\n","        file.write(data)"]},{"cell_type":"markdown","metadata":{"id":"Qfj4rdzqa8I1"},"source":["### Data Split : train -> train, val"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":328,"status":"ok","timestamp":1686563432618,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"mCdQFtVza8I1","outputId":"981b42dd-08dc-4002-a6e0-a6339c4a535a"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/animal_detection\n"]}],"source":["%cd ../.."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1686563471163,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"tayDRm3fa8I1","outputId":"77c394e0-abeb-4df1-9183-f612ddddb4ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["1204\n"]}],"source":["from glob import glob\n","\n","img_list = glob(\"/content/drive/MyDrive/animal_detection/dataset/images/train/*.jpg\")\n","print(len(img_list))"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1686563481542,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"USpRIFKNa8I2","outputId":"74645fdf-66b1-45a3-8e1e-b4328fbaed03"},"outputs":[{"name":"stdout","output_type":"stream","text":["1200\n"]}],"source":["# 1204개 이미지 중 1200개 사용\n","\n","import random\n","\n","random_image_path = random.sample(img_list, k=1200)\n","print(len(random_image_path))"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":913,"status":"ok","timestamp":1686563503538,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"gdkFM__ga8I2","outputId":"e8cf5e06-8c52-487b-ecaa-517e3fae77d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["960 240\n"]}],"source":["# train : val = 4 : 1\n","\n","from sklearn.model_selection import train_test_split\n","\n","train_img_list, val_img_list = train_test_split(random_image_path, test_size=0.2, random_state=2000)\n","\n","print(len(train_img_list), len(val_img_list))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686563520149,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"1G51-doY7x0I","outputId":"b409e685-9909-43a6-c093-e524c0c74018"},"outputs":[{"data":{"text/plain":["['/content/drive/MyDrive/animal_detection/dataset/images/train/1057.jpg',\n"," '/content/drive/MyDrive/animal_detection/dataset/images/train/0387.jpg',\n"," '/content/drive/MyDrive/animal_detection/dataset/images/train/0649.jpg',\n"," '/content/drive/MyDrive/animal_detection/dataset/images/train/0263.jpg',\n"," '/content/drive/MyDrive/animal_detection/dataset/images/train/0318.jpg']"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["train_img_list[:5]"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":243,"status":"ok","timestamp":1686563550399,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"B1HYXhxya8I2"},"outputs":[],"source":["# dataset 폴더 하위에 train, val 각각 경로 담긴 txt 파일 생성\n","\n","with open('./dataset/train.txt', 'w') as f:\n","    f.write('\\n'.join(train_img_list) + '\\n')\n","\n","with open('./dataset/val.txt', 'w') as f:\n","    f.write('\\n'.join(val_img_list) + '\\n')"]},{"cell_type":"markdown","metadata":{"id":"Otpkdokia8I2"},"source":["### yaml 파일 생성"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":437,"status":"ok","timestamp":1686563599197,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"fN2DA-yNa8I2","outputId":"87ce5d3a-a91b-47b1-99bc-f08af78a452e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/animal_detection/dataset\n"]}],"source":["%cd dataset"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686563622094,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"OBzIRgifa8I3"},"outputs":[],"source":["# data.yaml 작성\n","# 클래스 명, 클래스 개수, yaml경로, 나머지 경로 명시\n","\n","\n","import yaml\n","\n","data = {\n","    'names': ['buffalo', 'elephant', 'rhino', 'zebra'],\n","    'nc' : 4,\n","    'path': os.getcwd(),\n","    'train': os.path.join(os.getcwd(), 'train.txt'),\n","    'val': os.path.join(os.getcwd(), 'val.txt'),\n","    'test': None\n","}\n","\n","# data.yaml 파일에 데이터 작성\n","with open('data.yaml', 'w') as file:\n","    yaml.dump(data, file)"]},{"cell_type":"markdown","metadata":{"id":"rUDBYRIua8I3"},"source":["### Yolov5 training"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":371,"status":"ok","timestamp":1686563641020,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"QvIo2Yw2a8I3","outputId":"9d9a227b-00b7-4c98-d049-f57b7ffa0821"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/animal_detection/dataset'"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["pwd"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4164,"status":"ok","timestamp":1686563648214,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"91vbhsl7a8I3","outputId":"6d338882-b03a-4f9d-e0dc-23d633757df0"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/animal_detection\n","Cloning into 'yolov5'...\n","remote: Enumerating objects: 15978, done.\u001b[K\n","remote: Counting objects: 100% (147/147), done.\u001b[K\n","remote: Compressing objects: 100% (77/77), done.\u001b[K\n","remote: Total 15978 (delta 89), reused 110 (delta 70), pack-reused 15831\u001b[K\n","Receiving objects: 100% (15978/15978), 14.54 MiB | 14.24 MiB/s, done.\n","Resolving deltas: 100% (10963/10963), done.\n"]}],"source":["# YOLOv5 설치\n","\n","%cd ..\n","\n","!git clone https://github.com/ultralytics/yolov5.git"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5112,"status":"ok","timestamp":1686563655404,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"EYWmn_aga8I3","outputId":"be1aac6d-675c-41c4-f3db-3e1a8ffc073e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/animal_detection/yolov5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n","Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.15.2+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n","Collecting ultralytics>=8.0.111 (from -r requirements.txt (line 18))\n","  Downloading ultralytics-8.0.116-py3-none-any.whl (599 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.6/599.6 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n","Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n","Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (16.0.5)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2022.7.1)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 15)) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 15)) (1.3.0)\n","Installing collected packages: smmap, gitdb, gitpython, ultralytics, thop\n","Successfully installed gitdb-4.0.10 gitpython-3.1.31 smmap-5.0.0 thop-0.1.1.post2209072238 ultralytics-8.0.116\n"]}],"source":["%cd yolov5\n","\n","!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"l5aXHHzy3w7H"},"source":["### model train"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":888719,"status":"ok","timestamp":1686565749682,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"jHRrHJ9qa8I3","outputId":"5613872d-4702-46e7-eeee-a944caba2255"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/animal_detection/yolov5/models/yolov5s.pt, cfg=/content/drive/MyDrive/animal_detection/yolov5/models/yolov5s.yaml, data=/content/drive/MyDrive/animal_detection/dataset/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=32, imgsz=224, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=animal_weights, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 16.8MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to /content/drive/MyDrive/animal_detection/yolov5/models/yolov5s.pt...\n","100% 14.1M/14.1M [00:00<00:00, 96.2MB/s]\n","\n","Overriding model.yaml nc=80 with nc=4\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","YOLOv5s summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n","\n","Transferred 342/349 items from /content/drive/MyDrive/animal_detection/yolov5/models/yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/animal_detection/dataset/train... 960 images, 0 backgrounds, 0 corrupt: 100% 960/960 [00:04<00:00, 223.52it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/animal_detection/dataset/images/train/0773.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/animal_detection/dataset/images/train/1021.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/animal_detection/dataset/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/animal_detection/dataset/val... 240 images, 0 backgrounds, 0 corrupt: 100% 240/240 [00:01<00:00, 167.18it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/animal_detection/dataset/images/train/0160.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/animal_detection/dataset/images/train/1011.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/animal_detection/dataset/val.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.53 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/animal_weights/labels.jpg... \n","Image sizes 224 train, 224 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/animal_weights\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/29      1.04G    0.09832    0.02805    0.04548        138        224: 100% 30/30 [01:06<00:00,  2.23s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:05<00:00,  1.40s/it]\n","                   all        240        420     0.0728      0.367     0.0828     0.0248\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/29      1.05G    0.06381    0.02629    0.03752        125        224: 100% 30/30 [01:02<00:00,  2.08s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.10s/it]\n","                   all        240        420      0.253       0.62      0.334      0.113\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/29      1.05G    0.05945    0.02323    0.03204        134        224: 100% 30/30 [01:01<00:00,  2.05s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.24s/it]\n","                   all        240        420      0.371      0.706      0.481      0.226\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/29      1.05G    0.05664    0.02167    0.02768        130        224: 100% 30/30 [01:00<00:00,  2.02s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.05s/it]\n","                   all        240        420      0.332      0.751      0.549      0.286\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/29      1.05G    0.04982    0.01973    0.02404        139        224: 100% 30/30 [00:58<00:00,  1.94s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:06<00:00,  1.50s/it]\n","                   all        240        420       0.48      0.762      0.658      0.331\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/29      1.05G    0.04663    0.01958    0.01989        154        224: 100% 30/30 [00:55<00:00,  1.86s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.04it/s]\n","                   all        240        420       0.75      0.674      0.774      0.474\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/29      1.05G    0.04336    0.01903    0.01708        133        224: 100% 30/30 [01:02<00:00,  2.07s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:05<00:00,  1.36s/it]\n","                   all        240        420      0.816      0.766       0.83      0.464\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/29      1.05G    0.04141    0.01889    0.01315        141        224: 100% 30/30 [00:59<00:00,  1.97s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.10it/s]\n","                   all        240        420      0.807      0.797      0.822      0.486\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/29      1.05G    0.03863    0.01795    0.01136        122        224: 100% 30/30 [01:01<00:00,  2.05s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:05<00:00,  1.34s/it]\n","                   all        240        420      0.884      0.783      0.888      0.575\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/29      1.05G    0.03715    0.01791     0.0103        141        224: 100% 30/30 [00:57<00:00,  1.91s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.00it/s]\n","                   all        240        420      0.906      0.793      0.895      0.575\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/29      1.05G    0.03629    0.01783   0.009843        135        224: 100% 30/30 [01:01<00:00,  2.07s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.06s/it]\n","                   all        240        420      0.824      0.786      0.868      0.542\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/29      1.05G     0.0358    0.01824   0.009221        122        224: 100% 30/30 [01:01<00:00,  2.04s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:05<00:00,  1.49s/it]\n","                   all        240        420      0.853      0.858      0.916      0.631\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/29      1.05G    0.03512    0.01736   0.008744        151        224: 100% 30/30 [01:04<00:00,  2.14s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.08it/s]\n","                   all        240        420      0.905      0.792      0.906      0.646\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/29      1.05G    0.03309    0.01678   0.007952        135        224: 100% 30/30 [01:03<00:00,  2.10s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.19it/s]\n","                   all        240        420      0.887      0.829      0.907       0.63\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/29      1.05G    0.03289    0.01727   0.007611        151        224: 100% 30/30 [00:58<00:00,  1.95s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:05<00:00,  1.27s/it]\n","                   all        240        420      0.872      0.775      0.888      0.648\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/29      1.05G    0.03186    0.01725   0.007606        117        224: 100% 30/30 [01:02<00:00,  2.07s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.19it/s]\n","                   all        240        420      0.912      0.814      0.906      0.644\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/29      1.05G    0.03162    0.01645   0.006493        125        224: 100% 30/30 [01:00<00:00,  2.01s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:05<00:00,  1.29s/it]\n","                   all        240        420       0.91      0.831      0.913      0.676\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/29      1.05G    0.03157     0.0168   0.006322        137        224: 100% 30/30 [00:59<00:00,  1.97s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:05<00:00,  1.47s/it]\n","                   all        240        420      0.909      0.824      0.904      0.656\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/29      1.05G    0.03004    0.01619    0.00643        123        224: 100% 30/30 [00:59<00:00,  1.97s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:05<00:00,  1.36s/it]\n","                   all        240        420      0.938      0.813      0.928      0.704\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/29      1.05G    0.02993     0.0167   0.005899        149        224: 100% 30/30 [00:59<00:00,  1.99s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.19s/it]\n","                   all        240        420      0.945      0.851      0.931       0.71\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/29      1.05G    0.02901    0.01589   0.005519        146        224: 100% 30/30 [00:56<00:00,  1.89s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.01it/s]\n","                   all        240        420      0.924      0.827      0.927      0.705\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/29      1.05G    0.02814    0.01594   0.005562        133        224: 100% 30/30 [00:58<00:00,  1.95s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.18s/it]\n","                   all        240        420      0.922      0.828      0.927      0.703\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/29      1.05G     0.0279    0.01579   0.005841        106        224: 100% 30/30 [00:56<00:00,  1.89s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.09s/it]\n","                   all        240        420       0.95      0.841      0.931      0.708\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/29      1.05G    0.02784      0.016   0.004856        128        224: 100% 30/30 [01:02<00:00,  2.08s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.14s/it]\n","                   all        240        420      0.929      0.835       0.93      0.716\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/29      1.05G     0.0264    0.01513   0.005099        137        224: 100% 30/30 [00:58<00:00,  1.95s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.14it/s]\n","                   all        240        420       0.92      0.833      0.934       0.73\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/29      1.05G    0.02713    0.01555   0.004584        127        224: 100% 30/30 [01:01<00:00,  2.03s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.10s/it]\n","                   all        240        420      0.923      0.877      0.945      0.733\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      26/29      1.05G    0.02554     0.0152   0.004498        115        224: 100% 30/30 [00:59<00:00,  1.99s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.10s/it]\n","                   all        240        420      0.948      0.846      0.948      0.744\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      27/29      1.05G    0.02574    0.01493   0.004285        145        224: 100% 30/30 [01:01<00:00,  2.04s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.23s/it]\n","                   all        240        420       0.92      0.895       0.95       0.75\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      28/29      1.05G    0.02505    0.01456   0.004448        122        224: 100% 30/30 [00:57<00:00,  1.93s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.14it/s]\n","                   all        240        420      0.936      0.889      0.947      0.749\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      29/29      1.05G    0.02475    0.01498   0.003918        123        224: 100% 30/30 [00:59<00:00,  1.97s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.01it/s]\n","                   all        240        420      0.934      0.893      0.947      0.753\n","\n","30 epochs completed in 0.556 hours.\n","Optimizer stripped from runs/train/animal_weights/weights/last.pt, 14.3MB\n","Optimizer stripped from runs/train/animal_weights/weights/best.pt, 14.3MB\n","\n","Validating runs/train/animal_weights/weights/best.pt...\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:07<00:00,  1.87s/it]\n","                   all        240        420      0.935      0.893      0.947      0.752\n","               buffalo        240         92      0.966      0.913      0.967      0.832\n","              elephant        240         99      0.919      0.919      0.953      0.712\n","                 rhino        240         85      0.942      0.955      0.972       0.83\n","                 zebra        240        144      0.912      0.785      0.895      0.635\n","Results saved to \u001b[1mruns/train/animal_weights\u001b[0m\n"]}],"source":["!python train.py --img 224 --batch 32 --epochs 30 --data /content/drive/MyDrive/animal_detection/dataset/data.yaml --cfg /content/drive/MyDrive/animal_detection/yolov5/models/yolov5s.yaml --weights /content/drive/MyDrive/animal_detection/yolov5/models/yolov5s.pt --name animal_weights "]},{"cell_type":"markdown","metadata":{"id":"4UePw-KBa8I4"},"source":["### Yolov5 test"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1686566242147,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"johu4iTIE2uy","outputId":"45441b3c-a599-47c5-a3d8-7a0bdabcc83a"},"outputs":[{"name":"stdout","output_type":"stream","text":["300\n"]}],"source":["from glob import glob\n","\n","test_img_list = glob(\"/content/drive/MyDrive/animal_detection/dataset/images/test/*.jpg\")\n","print(len(test_img_list))"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":309,"status":"ok","timestamp":1686566259502,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"kbAMXfirE8z-"},"outputs":[],"source":["with open('/content/drive/MyDrive/animal_detection/dataset/test.txt', 'w') as f:\n","    f.write('\\n'.join(test_img_list) + '\\n')"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":383,"status":"ok","timestamp":1686566273989,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"J85L8RaQFshA","outputId":"6a09ebfa-c655-440f-fedd-a04d1c0b59c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'names': ['buffalo', 'elephant', 'rhino', 'zebra'], 'nc': 4, 'path': '/content/drive/MyDrive/animal_detection/dataset', 'test': None, 'train': '/content/drive/MyDrive/animal_detection/dataset/train.txt', 'val': '/content/drive/MyDrive/animal_detection/dataset/val.txt'}\n","{'names': ['buffalo', 'elephant', 'rhino', 'zebra'], 'nc': 4, 'path': '/content/drive/MyDrive/animal_detection/dataset', 'test': '/content/drive/MyDrive/animal_detection/dataset/test.txt', 'train': '/content/drive/MyDrive/animal_detection/dataset/train.txt', 'val': '/content/drive/MyDrive/animal_detection/dataset/val.txt'}\n"]}],"source":["# data.yaml에 test.txt경로 추가\n","\n","import yaml\n","\n","with open('/content/drive/MyDrive/animal_detection/dataset/data.yaml', 'r') as f:\n","    data = yaml.load(f, Loader=yaml.SafeLoader)\n","print(data)\n","\n","data['test'] = '/content/drive/MyDrive/animal_detection/dataset/test.txt' \n","\n","with open('/content/drive/MyDrive/animal_detection/dataset/data.yaml', 'w') as f:\n","    yaml.dump(data, f)\n","\n","print(data)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84502,"status":"ok","timestamp":1686566433471,"user":{"displayName":"김승재","userId":"04648942213885290519"},"user_tz":-540},"id":"B1H-VLiN_v5V","outputId":"2d6d6299-3f82-4847-ee02-c40f575c54e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING ⚠️ user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n","\u001b[34m\u001b[1mval: \u001b[0mdata=/content/drive/MyDrive/animal_detection/dataset/data.yaml, weights=['/content/drive/MyDrive/animal_detection/yolov5/runs/train/animal_weights/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.8, max_det=300, task=test, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n","YOLOv5 🚀 v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","\u001b[34m\u001b[1mtest: \u001b[0mScanning /content/drive/MyDrive/animal_detection/dataset/test... 300 images, 0 backgrounds, 0 corrupt: 100% 300/300 [00:01<00:00, 169.29it/s]\n","\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /content/drive/MyDrive/animal_detection/dataset/test.cache\n","                 Class     Images  Instances          P          R      mAP75   mAP50-95: 100% 10/10 [01:07<00:00,  6.75s/it]\n","                   all        300        558      0.778      0.449      0.414      0.369\n","               buffalo        300        124      0.809      0.371      0.322      0.298\n","              elephant        300        178      0.807      0.612      0.574      0.498\n","                 rhino        300        106      0.805      0.312      0.357      0.331\n","                 zebra        300        150      0.692        0.5      0.402       0.35\n","Speed: 0.2ms pre-process, 6.8ms inference, 2.0ms NMS per image at shape (32, 3, 640, 640)\n","Results saved to \u001b[1mruns/val/exp\u001b[0m\n","293 labels saved to runs/val/exp/labels\n"]}],"source":["!python val.py --task \"test\" --data /content/drive/MyDrive/animal_detection/dataset/data.yaml --weights /content/drive/MyDrive/animal_detection/yolov5/runs/train/animal_weights/weights/best.pt  --iou-thres 0.8 --device 0 --save-txt"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"fbba352725f312b06156d25d0e4c4846f04beb985608aefa695f1718f92fb570"}}},"nbformat":4,"nbformat_minor":0}
